import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.figure_factory as ff
import geopandas as gpd
import pydeck as pdk
import base64
from io import BytesIO
import requests
import json
from datetime import datetime
import time
import seaborn as sns
import matplotlib.pyplot as plt


st.set_page_config(layout='wide')


def to_excel(df):
    output = BytesIO()
    writer = pd.ExcelWriter(output, engine='xlsxwriter')
    df.to_excel(writer, sheet_name='Sheet1', index=False)
    writer.close()
    processed_data = output.getvalue()
    return processed_data

def get_table_download_link(df, file_name, file_label):
    """Generates a link allowing the data in a given panda dataframe to be downloaded
    in:  dataframe
    out: download link
    """
    val = to_excel(df)
    b64 = base64.b64encode(val)  # val looks like b'...'
    return f'<a href="data:application/octet-stream;base64,{b64.decode()}" download="{file_name}">{file_label}</a>'

def create_download_button(df, filename):
    excel_data = to_excel(df)
    b64 = base64.b64encode(excel_data).decode("utf-8")
    return st.download_button(
        label="ë‹¤ìš´ë¡œë“œ",
        data=BytesIO(base64.b64decode(b64)),
        file_name=filename,
        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
    )

# ì—°ë ¹ëŒ€ ê³„ì‚°ì„ ìœ„í•œ í•¨ìˆ˜
def calculate_age_group(age):
    if age < 30:
        return "20ëŒ€"
    elif age < 40:
        return "30ëŒ€"
    elif age < 50:
        return "40ëŒ€"
    elif age < 60:
        return "50ëŒ€"
    elif age < 70:
        return "60ëŒ€"
    else:
        return "70ëŒ€ ì´ìƒ"



uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=["csv", "xlsx", "xls"],key="unique_key_for_uploader")


if uploaded_file is not None:
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file, encoding='cp949')
        elif uploaded_file.name.endswith('.xlsx') or uploaded_file.name.endswith('.xls'):
            df = pd.read_excel(uploaded_file)
        
        df=df.drop(columns=['ì‹¤í–‰/í•´ì§€êµ¬ë¶„','ì”ì•¡(ì›)','ë³´ì¦ì¼ì','ë³´ì¦ê¸°í•œ','ì£¼ì±„ë¬´ê¸°í•œ','ì—…ì¢…ì½”ë“œ','ìƒí™˜êµ¬ë¶„','ë³´ì¦ì¢…ë¥˜','ìƒëŒ€ì²˜ì½”ë“œ','ìƒëŒ€ì²˜','ìê¸ˆì¢…ë¥˜','ìê¸ˆëª…','ê±´ë³„êµ¬ë¶„','ê·œëª¨','ê·œëª¨(ì¡°ì‚¬)','ë‹´ë‹¹íŒ€','ë‹´ë‹¹ì','ê³ ìš©ì¦ê°€ìˆ˜','ì‚¬ì—…ì¥ìš°í¸ë²ˆí˜¸','ì‚¬ì—…ì¥ìš°í¸ë²ˆí˜¸(ì¡°ì‚¬)','ì‚¬ì—…ì¥ì´í•˜ì£¼ì†Œ','ì‚¬ì—…ì¥ì „í™”ë²ˆí˜¸','ê±°ì£¼ì§€ì£¼ì†Œ','ê±°ì£¼ì§€ì´í•˜ì£¼ì†Œ','êµ¬ë¶„','ì¬ë³´ì¦ê¸°ê´€','ì¬ë³´ì¦ë¹„ìœ¨','ì¬ë³´ì¦ê¸ˆì•¡','ì‚¬ì—…ìêµ¬ë¶„','ì·¨ì†Œ/ì •ë‹¹','ë³´ì¦ë°©ë²•','ë‹´ë‹¹ë¶€ì ','ì¡°ì‚¬ì','ì—…ì²´ìƒíƒœ','ì²˜ë¦¬íŒ€','ì²˜ë¦¬ì','ìƒë‹´ì','ìƒë‹´ì…ë ¥ì','íœ´ëŒ€í°ë²ˆí˜¸','ì ‘ìˆ˜ê¸ˆì•¡','ì ‘ìˆ˜ì¼ì','ìƒë‹´ì¼ì','ìƒë‹´ê¸ˆì•¡','ì¡°ì‚¬ì¼ì','ì‹¬ì‚¬ì¼ì','ìŠ¹ì¸ì¼ì','í’ˆì˜ì¼ì','ì•½ì •ì¼ì','ì•½ì •ë“±ë¡ì¼ì','ìˆ˜ë‚©ì—¬ë¶€'])
        total_count = len(df)

        df['ê¸°í‘œì¼ì'] = pd.to_datetime(df['ê¸°í‘œì¼ì'], errors='coerce')  # ì´ ë¶€ë¶„ì„ í™•ì‹¤íˆ datetimeìœ¼ë¡œ ë³€í™˜
        df['ê¸°í‘œë…„ë„'] = pd.to_datetime(df['ê¸°í‘œì¼ì']).dt.year  # 'ê¸°í‘œë…„ë„' ì¶”ì¶œ
        df['ì‹¤í–‰/í•´ì§€ê¸ˆì•¡(ì›)'] = pd.to_numeric(df['ì‹¤í–‰/í•´ì§€ê¸ˆì•¡(ì›)'], errors='coerce')




        #----------------------sidebar-----------------------------------------------
        st.sidebar.title("í•„í„° ì˜µì…˜")

        selected_banks = st.sidebar.multiselect(
            "ì€í–‰ ì„ íƒ", options=['ì „ì²´ ì„ íƒ'] + list(df['ì€í–‰êµ¬ë¶„'].unique()), default=['ì „ì²´ ì„ íƒ'])
        
        selected_years = st.sidebar.multiselect(
            "ì—°ë„ ì„ íƒ", options=['ì „ì²´ ì„ íƒ'] + list(df['ê¸°í‘œë…„ë„'].unique()), default=['ì „ì²´ ì„ íƒ'])
        
        selected_industries = st.sidebar.multiselect(
            "ì—…ì¢… ì„ íƒ", options=['ì „ì²´ ì„ íƒ'] + list(df['ëŒ€ë¶„ë¥˜ì—…ì¢…ëª…'].unique()), default=['ì „ì²´ ì„ íƒ'])

        min_date = df['ê¸°í‘œì¼ì'].min().date()
        max_date = df['ê¸°í‘œì¼ì'].max().date()
        selected_date_range = st.sidebar.slider(
            "ê¸°í‘œì¼ì ë²”ìœ„ ì„ íƒ", min_date, max_date, (min_date, max_date))

        filtered_df = df.copy()

        if 'ì „ì²´ ì„ íƒ' not in selected_banks:
            filtered_df = filtered_df[filtered_df['ì€í–‰êµ¬ë¶„'].isin(selected_banks)]
        if 'ì „ì²´ ì„ íƒ' not in selected_years:
            filtered_df = filtered_df[filtered_df['ê¸°í‘œë…„ë„'].isin(selected_years)]
        if 'ì „ì²´ ì„ íƒ' not in selected_industries:
            filtered_df = filtered_df[filtered_df['ëŒ€ë¶„ë¥˜ì—…ì¢…ëª…'].isin(selected_industries)]

        start_date, end_date = pd.Timestamp(selected_date_range[0]), pd.Timestamp(selected_date_range[1])
        filtered_df = filtered_df[(filtered_df['ê¸°í‘œì¼ì'] >= start_date) & (filtered_df['ê¸°í‘œì¼ì'] <= end_date)]
























        #-----------------Dashboard-------------------------------------------
        # Custom CSS
        st.markdown("""
            <style>
            .big-font {
                font-size:30px !important;
                font-weight: bold;
            }
            .info-box {
                background-color: lightblue;
                padding: 10px;
                border-radius: 10px;
                margin: 10px 0;
            }
            .dataframe table {
                color: #343a40;
            }
            .dataframe th {
                background-color: #f0ad4e;
                color: white;
            }
            .dataframe td, .dataframe th {
                border: 1px solid white;
                padding: 10px;
                text-align: center;
            }
            .plotly-graph-div {
                box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
                transition: 0.3s;
            }
            .plotly-graph-div:hover {
                box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
            }
            </style>
            """, unsafe_allow_html=True)
        
        # ëŒ€ì‹œë³´ë“œ íƒ€ì´í‹€ ë° íŒŒì¼ ì—…ë¡œë“œ ì •ë³´
        st.markdown('<div class="big-font">ğŸŒŸ ë³´ì¦ ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ ğŸŒŸ</div>', unsafe_allow_html=True)
        st.markdown(f"<div class='info-box'>ğŸ“Š ì—…ë¡œë“œëœ íŒŒì¼ ì´ ë°ì´í„° ìˆ˜: {format(total_count, ',')}ê±´</div>", unsafe_allow_html=True)
        
        # ë°ì´í„° ì‹œê°í™” - ì€í–‰ë³„ ëŒ€ì¶œ ê·œëª¨
        bank_loan_size = filtered_df.groupby('ì€í–‰êµ¬ë¶„')['ì°¨ì…ê¸ˆ(ìš´ì „)'].sum().reset_index()
        st.markdown("## ğŸ’¼ ì€í–‰ë³„ ëŒ€ì¶œ ê·œëª¨", unsafe_allow_html=True)
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("<h3 style='text-align: center; color: black;'>ëŒ€ì¶œ ê·œëª¨ ë°” ì°¨íŠ¸</h3>", unsafe_allow_html=True)
            fig2 = px.bar(bank_loan_size, x='ì€í–‰êµ¬ë¶„', y='ì°¨ì…ê¸ˆ(ìš´ì „)', text='ì°¨ì…ê¸ˆ(ìš´ì „)')
            fig2.update_traces(texttemplate='%{text:.2s}', textposition='outside')
            fig2.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')
            st.plotly_chart(fig2, use_container_width=True)
            
        with col2:
            st.markdown("<h3 style='text-align: center; color: black;'>ëŒ€ì¶œ ê·œëª¨ íŒŒì´ ì°¨íŠ¸</h3>", unsafe_allow_html=True)
            fig1 = px.pie(bank_loan_size, names='ì€í–‰êµ¬ë¶„', values='ì°¨ì…ê¸ˆ(ìš´ì „)', hole=.3)
            fig1.update_traces(textinfo='percent+label')
            st.plotly_chart(fig1, use_container_width=True)
        
        # ë¶„ê¸°ë³„ ëŒ€ì¶œ ê¸ˆì•¡ ë° ëŒ€ì¶œ ê±´ìˆ˜
        st.markdown("## ğŸ“ˆ ë¶„ê¸°ë³„ ëŒ€ì¶œ ë™í–¥", unsafe_allow_html=True)
        loan_amount_by_quarter = filtered_df.resample('Q', on='ê¸°í‘œì¼ì')['ì‹¤í–‰/í•´ì§€ê¸ˆì•¡(ì›)'].sum().reset_index()
        loan_amount_by_quarter['ê¸°í‘œì¼ì'] = loan_amount_by_quarter['ê¸°í‘œì¼ì'].dt.to_period("Q").astype(str)

        loan_count_by_quarter = filtered_df.resample('Q', on='ê¸°í‘œì¼ì').size().reset_index(name='ëŒ€ì¶œê±´ìˆ˜')
        loan_count_by_quarter['ê¸°í‘œì¼ì'] = loan_count_by_quarter['ê¸°í‘œì¼ì'].dt.to_period("Q").astype(str)

        loan_stats = loan_amount_by_quarter['ì‹¤í–‰/í•´ì§€ê¸ˆì•¡(ì›)'].describe()
        
        col3, col4 = st.columns([3, 2])
        with col3:
            st.markdown("<h3 style='text-align: center; color: black;'>ë¶„ê¸°ë³„ ëŒ€ì¶œ ê¸ˆì•¡ ë³€í™”</h3>", unsafe_allow_html=True)
            fig6 = px.line(loan_amount_by_quarter, x='ê¸°í‘œì¼ì', y='ì‹¤í–‰/í•´ì§€ê¸ˆì•¡(ì›)', markers=True)
            fig6.update_layout(xaxis_title="ë¶„ê¸°", yaxis_title="ëŒ€ì¶œê¸ˆì•¡ (ì›)")
            st.plotly_chart(fig6, use_container_width=True)
            
        with col4:
            st.markdown("<h3 style='text-align: center; color: black;'>ë¶„ê¸°ë³„ ëŒ€ì¶œ ê±´ìˆ˜</h3>", unsafe_allow_html=True)
            fig7 = px.bar(loan_count_by_quarter, x='ê¸°í‘œì¼ì', y='ëŒ€ì¶œê±´ìˆ˜')
            fig7.update_layout(xaxis_title="ë¶„ê¸°", yaxis_title="ëŒ€ì¶œê±´ìˆ˜")
            st.plotly_chart(fig7, use_container_width=True)
        
        # ì—…ì¢…ë³„ ëŒ€ì¶œ ì •ë³´ ë° ì—°ë ¹ëŒ€ ë¶„í¬
        industry_loan_size = filtered_df.groupby('ëŒ€ë¶„ë¥˜ì—…ì¢…ëª…')['ì°¨ì…ê¸ˆ(ìš´ì „)'].sum().reset_index()
        industry_loan_count = filtered_df.groupby('ëŒ€ë¶„ë¥˜ì—…ì¢…ëª…').size().reset_index(name='ëŒ€ì¶œê±´ìˆ˜')
        industry_loan_combined = pd.merge(industry_loan_size, industry_loan_count, on='ëŒ€ë¶„ë¥˜ì—…ì¢…ëª…')
        industry_loan_combined = industry_loan_combined.sort_values(by=['ì°¨ì…ê¸ˆ(ìš´ì „)', 'ëŒ€ì¶œê±´ìˆ˜'], ascending=[False, False])
        industry_loan_combined['ì°¨ì…ê¸ˆ(ìš´ì „)'] = industry_loan_combined['ì°¨ì…ê¸ˆ(ìš´ì „)'].apply(lambda x: f"{x / 1e6:,.0f}ë°±ë§Œì›")
        
        st.markdown("## ğŸ­ ì—…ì¢…ë³„ ëŒ€ì¶œ ì •ë³´", unsafe_allow_html=True)
        st.dataframe(industry_loan_combined.style.highlight_max(axis=0))
        
        st.markdown("## ğŸ” ì—…ì¢…ë³„ ì—°ë ¹ëŒ€ ë¶„í¬", unsafe_allow_html=True)
        
        current_year = datetime.now().year
        
        filtered_df['ìƒë…„'] = filtered_df['ì£¼ë¯¼ë²ˆí˜¸'].str[:2].astype(int)
        filtered_df['ìƒë…„'] = filtered_df['ìƒë…„'].apply(lambda x: 1900+x if x > 22 else 2000+x)  # 22ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 1900ë…„ëŒ€ì™€ 2000ë…„ëŒ€ êµ¬ë¶„
        filtered_df['ë‚˜ì´'] = current_year - filtered_df['ìƒë…„']
        filtered_df['ì—°ë ¹ëŒ€'] = filtered_df['ë‚˜ì´'].apply(calculate_age_group)
        filtered_df['ì‹¤í–‰/í•´ì§€ê¸ˆì•¡(ì›)'] = pd.to_numeric(filtered_df['ì‹¤í–‰/í•´ì§€ê¸ˆì•¡(ì›)'], errors='coerce')
        
        industry_age_distribution = filtered_df.groupby(['ëŒ€ë¶„ë¥˜ì—…ì¢…ëª…', 'ì—°ë ¹ëŒ€']).size().reset_index(name='ê³ ê° ìˆ˜')
        industry_age_distribution_pivot = industry_age_distribution.pivot(index='ëŒ€ë¶„ë¥˜ì—…ì¢…ëª…', columns='ì—°ë ¹ëŒ€', values='ê³ ê° ìˆ˜')
        
        fig8 = px.imshow(industry_age_distribution_pivot,
                         labels=dict(x="ì—°ë ¹ëŒ€", y="ì—…ì¢…", color="ê³ ê° ìˆ˜"),
                         x=industry_age_distribution_pivot.columns,
                         y=industry_age_distribution_pivot.index,
                         aspect="auto",
                         color_continuous_scale="Viridis")
        fig8.update_layout(title="ì—…ì¢…ë³„ ì—°ë ¹ëŒ€ ë¶„í¬", xaxis_nticks=36)
        st.plotly_chart(fig8, use_container_width=True)
        
        # ê³ ê° ì—°ë ¹ ë¶„í¬ ë° ì—°ë ¹ëŒ€ë³„ ëŒ€ì¶œê¸ˆì•¡
        st.markdown("## ğŸ§‘â€ğŸ’¼ ê³ ê° ì—°ë ¹ ë¶„í¬ ë° ëŒ€ì¶œ ë¶„ì„", unsafe_allow_html=True)
            
        filtered_df['ìƒë…„'] = filtered_df['ì£¼ë¯¼ë²ˆí˜¸'].str[:2].astype(int)
        filtered_df['ìƒë…„'] = filtered_df['ìƒë…„'].apply(lambda x: 1900+x if x > 22 else 2000+x)  # 22ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 1900ë…„ëŒ€ì™€ 2000ë…„ëŒ€ êµ¬ë¶„
        filtered_df['ë‚˜ì´'] = current_year - filtered_df['ìƒë…„']
        filtered_df['ì—°ë ¹ëŒ€'] = filtered_df['ë‚˜ì´'].apply(calculate_age_group)
        filtered_df['ì‹¤í–‰/í•´ì§€ê¸ˆì•¡(ì›)'] = pd.to_numeric(filtered_df['ì‹¤í–‰/í•´ì§€ê¸ˆì•¡(ì›)'], errors='coerce')
        
        col5, col6 = st.columns(2)
        with col5:
            st.markdown("<h3 style='text-align: center; color: black;'>ê³ ê° ì—°ë ¹ ë¶„í¬</h3>", unsafe_allow_html=True)
            fig = px.bar(age_distribution, x='ë‚˜ì´', y='ê³ ê° ìˆ˜', color='ê³ ê° ìˆ˜')
            fig.update_layout(coloraxis_showscale=False)
            st.plotly_chart(fig, use_container_width=True)
            
        with col6:
            st.markdown("<h3 style='text-align: center; color: black;'>ì—°ë ¹ëŒ€ë³„ ëŒ€ì¶œê¸ˆì•¡</h3>", unsafe_allow_html=True)
            fig = px.pie(loan_amount_by_age_group, names='ì—°ë ¹ëŒ€', values='ì‹¤í–‰/í•´ì§€ê¸ˆì•¡(ì›)', hole=.3)
            fig.update_traces(textinfo='percent+label')
            st.plotly_chart(fig, use_container_width=True)
        
        
        
   
        #-------------ì§€ë„ì—ì„œ ìì¹˜êµ¬ë³„ ëŒ€ì¶œê·œëª¨ í™•ì¸-------------------------------------------------------------
        
        
        if st.sidebar.button('ìì¹˜êµ¬ë³„ ëŒ€ì¶œê·œëª¨ í™•ì¸'):
            # 'ì‚¬ì—…ì¥ì£¼ì†Œ'ì—ì„œ ì„œìš¸ ì§€ì—­ê³¼ ìì¹˜êµ¬ ì •ë³´ ì¶”ì¶œ
            seoul_df = filtered_df[filtered_df['ì‚¬ì—…ì¥ì£¼ì†Œ'].str.contains('ì„œìš¸íŠ¹ë³„ì‹œ', na=False)]
            seoul_df['ìì¹˜êµ¬'] = seoul_df['ì‚¬ì—…ì¥ì£¼ì†Œ'].str.split().str.get(1)  # None ë°˜í™˜ if IndexError

            # GeoJSON íŒŒì¼ ë¡œë”©
            gdf = gpd.read_file("HangJeongDong_ver20230701.geojson")

            # ìì¹˜êµ¬ë³„ ëŒ€ì¶œ ê·œëª¨ ê³„ì‚°
            loan_by_district = seoul_df.groupby('ìì¹˜êµ¬')['ì‹¤í–‰/í•´ì§€ê¸ˆì•¡(ì›)'].sum().reset_index()
            loan_by_district.columns = ['ìì¹˜êµ¬', 'ëŒ€ì¶œ ê·œëª¨']

            # GeoJSON ë°ì´í„°ì˜ geometry ì •ë³´ë¥¼ ì´ìš©í•˜ì—¬ ê° ìì¹˜êµ¬ì˜ ëŒ€í‘œì ì¸ ì¢Œí‘œ(ì¤‘ì‹¬)ë¥¼ ê³„ì‚°
            gdf['center'] = gdf['geometry'].apply(lambda x: x.representative_point().coords[:])
            gdf['center'] = gdf['center'].apply(lambda x: x[0])

            # ìì¹˜êµ¬ ì´ë¦„ê³¼ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥
            district_to_coords = {row['sggnm']: (row['center'][1], row['center'][0]) for idx, row in gdf.iterrows()}

            # ì„œìš¸ ë°ì´í„°ì—ì„œ ìì¹˜êµ¬ ì •ë³´ê°€ ìˆëŠ” í–‰ë§Œ ì„ íƒí•˜ê³ , ê° ìì¹˜êµ¬ì˜ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€
            seoul_df = seoul_df[seoul_df['ìì¹˜êµ¬'].isin(district_to_coords.keys())]
            seoul_df['lat'] = seoul_df['ìì¹˜êµ¬'].apply(lambda x: district_to_coords[x][0])
            seoul_df['lon'] = seoul_df['ìì¹˜êµ¬'].apply(lambda x: district_to_coords[x][1])

            # ìì¹˜êµ¬ë³„ ëŒ€ì¶œ ê·œëª¨ ê³„ì‚°
            loan_by_district = seoul_df.groupby('ìì¹˜êµ¬')['ì‹¤í–‰/í•´ì§€ê¸ˆì•¡(ì›)'].sum().reset_index()
            loan_by_district.columns = ['ìì¹˜êµ¬', 'ëŒ€ì¶œ ê·œëª¨']

            # ì¢Œí‘œì™€ ëŒ€ì¶œ ê·œëª¨ë¥¼ í•©ì¹œ ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            map_data = seoul_df[['ìì¹˜êµ¬', 'lat', 'lon']].drop_duplicates().merge(loan_by_district, on='ìì¹˜êµ¬')

            # ì¢Œí‘œì™€ ëŒ€ì¶œ ê·œëª¨ë¥¼ í•©ì¹œ ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            seoul_df['lat'] = seoul_df['ìì¹˜êµ¬'].apply(lambda x: district_to_coords.get(x, (None, None))[0])
            seoul_df['lon'] = seoul_df['ìì¹˜êµ¬'].apply(lambda x: district_to_coords.get(x, (None, None))[1])
            map_data = seoul_df[['ìì¹˜êµ¬', 'lat', 'lon']].drop_duplicates().merge(loan_by_district, on='ìì¹˜êµ¬')

            # ëŒ€ì¶œ ê·œëª¨ì˜ ìµœëŒ€ê°’ê³¼ ìµœì†Œê°’ì„ ê³„ì‚°í•˜ì—¬ ì •ê·œí™” (ë¹„ìœ¨ë¡œ í‘œí˜„)
            map_data['ëŒ€ì¶œ ê·œëª¨'] = pd.to_numeric(map_data['ëŒ€ì¶œ ê·œëª¨'], errors='coerce')
            max_loan = map_data['ëŒ€ì¶œ ê·œëª¨'].max()
            min_loan = map_data['ëŒ€ì¶œ ê·œëª¨'].min()



            # ëŒ€ì¶œ ê·œëª¨ë¥¼ ì •ê·œí™”í•˜ì—¬ ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€
            map_data['normalized_loan'] = (map_data['ëŒ€ì¶œ ê·œëª¨'] - min_loan) / (max_loan - min_loan)

            map_data['ëŒ€ì¶œ ê·œëª¨ (ë°±ë§Œ ë‹¨ìœ„)'] = map_data['ëŒ€ì¶œ ê·œëª¨'] / 1e7

            # ì„œìš¸ ì¤‘êµ¬ì˜ ëŒ€í‘œì ì¸ ì¢Œí‘œ (ìœ„ë„, ê²½ë„)
            seoul_junggu_coords = (37.5637, 126.9970)

            # map_dataì—ì„œ 'ì¤‘êµ¬'ì— í•´ë‹¹í•˜ëŠ” í–‰ì˜ ì¢Œí‘œë¥¼ ì—…ë°ì´íŠ¸
            map_data.loc[map_data['ìì¹˜êµ¬'] == 'ì¤‘êµ¬', 'lat'] = seoul_junggu_coords[0]
            map_data.loc[map_data['ìì¹˜êµ¬'] == 'ì¤‘êµ¬', 'lon'] = seoul_junggu_coords[1]

            # ì„œìš¸ ê°•ì„œêµ¬ì˜ ëŒ€í‘œì ì¸ ì¢Œí‘œ (ìœ„ë„, ê²½ë„)
            seoul_gangseogu_coords = (37.5510, 126.8495)

            # map_dataì—ì„œ 'ê°•ì„œêµ¬'ì— í•´ë‹¹í•˜ëŠ” í–‰ì˜ ì¢Œí‘œë¥¼ ì—…ë°ì´íŠ¸
            map_data.loc[map_data['ìì¹˜êµ¬'] == 'ê°•ì„œêµ¬', 'lat'] = seoul_gangseogu_coords[0]
            map_data.loc[map_data['ìì¹˜êµ¬'] == 'ê°•ì„œêµ¬', 'lon'] = seoul_gangseogu_coords[1]

            # Pydeck Layer ìƒì„±
            layer = pdk.Layer(
                "ScatterplotLayer",
                map_data,
                get_position=["lon", "lat"],
                get_radius="normalized_loan * 1000",
                get_fill_color=[255, 0, 0, 160],  # RGBA
                pickable=True,
                auto_highlight=True
            )

            # Pydeck Chart ìƒì„±
            tooltip = {
                "html": "<b>ìì¹˜êµ¬:</b> {ìì¹˜êµ¬} <br/> <b>ëŒ€ì¶œ ê·œëª¨:</b> {ëŒ€ì¶œ ê·œëª¨}",
                "style": {"backgroundColor": "steelblue", "color": "white"}
            }

            # ì§€ë„ ë Œë”ë§
            view_state = pdk.ViewState(latitude=37.5665, longitude=126.9780, zoom=10)
            deck_chart = pdk.Deck(layers=[layer], initial_view_state=view_state, tooltip=tooltip)

            st.subheader("ì§€ë„ì—ì„œ ìì¹˜êµ¬ë³„ ëŒ€ì¶œê·œëª¨ í™•ì¸í•˜ê¸°")
            # Streamlitì— ì§€ë„ í‘œì‹œ
            st.pydeck_chart(deck_chart)
            
            
            














            
            
            
        #-------------êµ­ì„¸ì²­ ìë£Œ í™•ì¸í•˜ëŠ” ë©”ë‰´------------------------------------------------------------- 
        if st.sidebar.button('êµ­ì„¸ì²­ ìë£Œë¡œ íœ´íì—…ì¡°íšŒ í•˜ê¸°'):
            if 'ì‚¬ì—…ìë²ˆí˜¸' in filtered_df.columns:
                business_numbers = filtered_df['ì‚¬ì—…ìë²ˆí˜¸'].dropna().unique()
                business_df = pd.DataFrame({
                    'ì‚¬ì—…ìë²ˆí˜¸': business_numbers
                })
            
                api_url = "https://api.odcloud.kr/api/nts-businessman/v1/status?serviceKey=ZW3%2Fwm7g8jKANr9RV4x%2Fc290L6dFdXB65VGs%2BQgvIbj%2FYScynUFaronWvB3%2FisFXzkKDLqoRpALKT%2FJ5gMe6yA%3D%3D"
                headers = {'Content-Type': 'application/json', 'Accept': 'application/json'}
                
                status_info = {}
                progress_bar = st.progress(0)
                total = len(business_numbers)
                status_text = st.empty()
                chunks = [business_numbers[i:i + 100] for i in range(0, len(business_numbers), 100)]
                
                completed = 0

                MAX_RETRIES = 3
                RETRY_DELAY = 5  # 5ì´ˆ ëŒ€ê¸°

                for chunk in chunks:
                    success = False
                    retries = 0
                    while not success and retries < MAX_RETRIES:
                        try:
                            payload_dict = {"b_no": [str(b_id.replace("-", "")) for b_id in chunk]}
                            response = requests.post(api_url, headers=headers, json=payload_dict)
                            
                            if response.status_code == 200:
                                result = response.json()
                                if 'data' in result:
                                    for data_entry in result['data']:
                                        b_id = data_entry.get('b_no', '')
                                        status = data_entry.get('b_stt', 'ì •ë³´ ì—†ìŒ')
                                        end_date = data_entry.get('end_dt', 'ì •ë³´ ì—†ìŒ')
                                        status_info[b_id] = {'ì˜ì—…ìƒíƒœ': status, 'íì—…ì¼': end_date}
                                    success = True
                            elif response.status_code != 200:
                                retries += 1
                                time.sleep(RETRY_DELAY)
                        except (requests.ConnectionError, requests.Timeout):
                            retries += 1
                            if retries < MAX_RETRIES:
                                time.sleep(RETRY_DELAY)

                    completed += len(chunk)
                    progress = completed / total
                    progress_bar.progress(progress)
                    status_text.text(f"ì´ {total}ê°œ ì¤‘ {completed}ê°œ ì™„ë£Œ ({progress * 100:.2f}%)")

                    if not success:
                        st.warning(f"ì‚¬ì—…ìë²ˆí˜¸ {chunk}ì— ëŒ€í•œ ìš”ì²­ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

                                
                progress_bar.progress(1.0)
                st.markdown(f"### ğŸ“ˆ ì´ {total}ê°œ ì¤‘ {total}ê°œ ì™„ë£Œ (100%) ğŸ‰")
                
                original_df = filtered_df
                original_df['ì‚¬ì—…ìë²ˆí˜¸'] = original_df['ì‚¬ì—…ìë²ˆí˜¸'].apply(lambda x: str(x).replace('-', ''))
                
                status_df = pd.DataFrame.from_dict(status_info, orient='index').reset_index()
                status_df.columns = ['ì‚¬ì—…ìë²ˆí˜¸', 'ì˜ì—…ìƒíƒœ', 'íì—…ì¼']
                
                merged_df = pd.merge(original_df, status_df, on='ì‚¬ì—…ìë²ˆí˜¸', how='left')
                
                st.markdown("## ğŸ“ íœ´íì—… ì¡°íšŒê²°ê³¼ ë‹¤ìš´ë¡œë“œ ë°›ê¸° ğŸ“¥")
                create_download_button(merged_df, "íœ´íì—…ì¡°íšŒê²°ê³¼.xlsx")
            
                          
                            #CBì ìˆ˜ -> CBë“±ê¸‰ìœ¼ë¡œ ì „í™˜
                            #CBë“±ê¸‰ì— ë”°ë¥¸ ëŒ€ì¶œê·œëª¨ ë¶„í¬
                            #ìƒì¡´ìœ¨ ë˜ëŠ” íì—…ë¥ 











        

    except Exception as e:
        st.write("íŒŒì¼ì„ ì½ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        st.write(e)
else:
    st.write("ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")        
